{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants & Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10 + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Hello World\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'10' + '20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10\n",
    "_a = 10\n",
    "a123 = 10\n",
    "# 1 = 10    not allowed\n",
    "# 1a = 10   not allowed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10          # integer / int\n",
    "b = True        # boolean / bool\n",
    "s = 'String'    # string / str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(a))\n",
    "print(type(b))\n",
    "print(type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a) == int\n",
    "type(b) == bool\n",
    "type(s) == str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Help for Variables and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee = '1, Scott, Tiger, 1000.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(employee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(employee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(str) # to get docs for str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal = 1000\n",
    "help (sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(int) # help for int, same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int? # only works in the iPython environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(str.capitalize) # get help for this specific function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(employee) # show all of the functions available on this variables Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Manipulation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = '1,2022-10-01 00:00:00.0,1,COMPLETE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_parts = order.split(',') # split the string into a list of its parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_parts[3].lower() # lower case status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(string_parts[0]) # cast the first item to an Integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = [125, 205, 183, 312]\n",
    "cities = ['Dallas', 'Frisco', 'Hyderabad', 'Bengaluru']\n",
    "score = [75, 80, 95, None, 'Absent', 65]    # Lists can mix Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Items in the List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[0]    # get the first item\n",
    "sales[-1]   # get the last item\n",
    "sales[1:3]  # get the second and third item\n",
    "sales[1:]   # get from the index to the last item\n",
    "sales[:3]   # get the first element to the 3rd element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cities) # get the length of a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(sales) # sum the values of Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(score)    can't do this, the elements are different Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loops and Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = [125, 205, 183, 312]\n",
    "cities = ['Dallas', 'Frisco', 'Hyderabad', 'Bengaluru']\n",
    "scores = [75, 80, 95, None, 'Absent', 65]    # Lists can mix Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in cities: # regular FOR loop\n",
    "    print(f'Length of {city} is {len(city)}')   # String Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "\n",
    "for score in scores:    # Filtering by type with FOR and IF\n",
    "    if type(score) == int:\n",
    "        total += score\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = input('Enter a number: ')  # Read console input\n",
    "number_as_int = int(number)\n",
    "result = (number_as_int * (number_as_int + 1)) / 2\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumN(n):\n",
    "    return  (n * (n + 1)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumN(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumRange(lower, upper):\n",
    "    return sumN(upper) - sumN(lower - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumRange(5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_file = open('./data/retail_db/orders/part-00000')\n",
    "\n",
    "order_str = orders_file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading File into List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_file = open('./data/retail_db/orders/part-00000')\n",
    "\n",
    "order_str = orders_file.read()\n",
    "\n",
    "order_elements = order_str.splitlines() # split by \\n character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List\n",
    "\n",
    "Groups of similar elements, need not be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_file = open('./data/retail_db/orders/part-00000')\n",
    "\n",
    "order_str = orders_file.read()\n",
    "\n",
    "order_elements = order_str.splitlines() # split by \\n character\n",
    "\n",
    "first_ten_orders = order_elements[:10]\n",
    "\n",
    "first_ten_orders[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set\n",
    "\n",
    "Group of similar elements, must be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = {1,2,2,3,4,5,6,3} # Sets automatically delete duplicates\n",
    "\n",
    "s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuple\n",
    "\n",
    "Group of elements of different Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_tuple = (2, '2013-07-25 00:00:00.0', 256, 'PENDING_PAYMENT')\n",
    "\n",
    "order_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary\n",
    "\n",
    "Group of Key/Value pairs where Keys must be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_dictionary = {\n",
    "    'order_id': 2,\n",
    "    'order_date': '2013-07-25 00:00:00.0',\n",
    "    'order_customer_id': 256,\n",
    "    'order_status': 'PENDING_PAYMENT'\n",
    "}\n",
    "\n",
    "order_dictionary.get('order_id') # get the value for the given key\n",
    "order_dictionary['order_id'] # same as above, except...\n",
    "\n",
    "# order_dictionary['id'] throws a KeyError Exception whereas...\n",
    "# type(order_dictionary.get('id') just returns NoneType\n",
    "     \n",
    "order_dictionary.keys() # list all of the keys\n",
    "\n",
    "order_dictionary.values() # list all values\n",
    "\n",
    "order_dictionary.items() # list keys and values as Tuples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Python Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions like len(), min(), max() and filter() will work on any of the Iterable Types listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_file = open('./data/retail_db/orders/part-00000')\n",
    "\n",
    "order_str = orders_file.read()\n",
    "\n",
    "orders = order_str.splitlines() # split by \\n character\n",
    "\n",
    "print(len(orders))\n",
    "print(min(orders))\n",
    "print(max(orders))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of Named Function: Print the Sum of all Integers up to the current Integer in the List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumN(n):\n",
    "    return (n * (n + 1)) / 2\n",
    "\n",
    "numbers = [1,2,3,4]\n",
    "\n",
    "[sumN(n) for n in numbers] # Example of List Comprehension, a shorthand for when you want to complete a simple operation against a List\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verbose example of Lambda Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumN_lambda = lambda n: (n * (n + 1)) / 2 # Lambdas can only have one statement/operation, therefore no Return statements\n",
    "\n",
    "sumN_lambda(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambdas with List Comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(n * (n + 1)) / 2 for n in numbers] # the operation just goes inline with the iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Lambda Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumN(n):\n",
    "    return (n * (n + 1)) / 2\n",
    "\n",
    "numbers = [1,2,3,4]\n",
    "\n",
    "list(map(sumN, numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1,2,3,4]\n",
    "\n",
    "list(map(lambda n: (n * (n + 1)) / 2, numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Data with Filter and Lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_file = open('./data/retail_db/orders/part-00000')\n",
    "\n",
    "order_str = orders_file.read()\n",
    "\n",
    "orders = order_str.splitlines() # split by \\n character\n",
    "\n",
    "list(filter(lambda o: o.split(',')[3] == \"COMPLETE\", orders)) # Item at Index 3\n",
    "list(filter(lambda o: o.split(',')[-1] == \"COMPLETE\", orders)) # Item at Last Index\n",
    "list(filter(lambda o: o.split(',')[3] in (\"COMPLETE\", \"CLOSED\"), orders)) # Filter by a List of options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Unique Values with Map and Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_file = open('./data/retail_db/orders/part-00000')\n",
    "\n",
    "order_str = orders_file.read()\n",
    "\n",
    "orders = order_str.splitlines() # split by \\n character\n",
    "\n",
    "list(map(lambda o: o.split(',')[3], orders)) # every Order Status in the Data\n",
    "set(map(lambda o: o.split(',')[3], orders)) # the collection of UNIQUE Order Statuses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting Lists with Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_file = open('./data/retail_db/orders/part-00000')\n",
    "\n",
    "order_str = orders_file.read()\n",
    "\n",
    "orders = order_str.splitlines() # split by \\n character\n",
    "\n",
    "list(sorted(orders, key = lambda o: int(o.split(',')[2]))) # sort the List with the custom Key function that finds the Customer ID, ASCENDING ORDER\n",
    "list(sorted(orders, key = lambda o: int(o.split(',')[2]), reverse = True)) # DESCENDING ORDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON Strings and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_json = '{\\\"order_id\\\": 1, \\\"order_date\\\": \\\"2013-07-25\\\"}'\n",
    "cities_json_arrray = '[\\\"Dallas\\\", \\\"Frisco\\\", \\\"Hyderabad\\\"]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading JSON Strings into Dicts or Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.loads    # Deserialize a JSON String into a Python Object, Dict by default\n",
    "\n",
    "order_json = '{\"order_id\": 1, \"order_date\": \"2013-07-25\"}'\n",
    "cities_json_arrray = '[\"Dallas\", \"Frisco\", \"Hyderabad\"]'\n",
    "\n",
    "import json\n",
    "\n",
    "order = json.loads(order_json)  # Deserializes into a Dict that matches the Key/Value Pairs in the JSON String\n",
    "\n",
    "order.get('order_id')\n",
    "\n",
    "cities = json.loads(cities_json_arrray) # Because Cities is a JSON Array, it gets Deserialized into a List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading JSON Files into Dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.load     # Deserialise a JSON File into a Python Object, Dict by default\n",
    "\n",
    "import json\n",
    "\n",
    "schemas_file = open('./data/retail_db/schemas.json')\n",
    "\n",
    "schemas_dict = json.load(schemas_file)\n",
    "schemas_dict.keys()\n",
    "schemas_dict.get('orders')\n",
    "schemas_dict['orders']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing JSON Data using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "schemas_file = open('./data/retail_db/schemas.json')\n",
    "\n",
    "schemas_dict = json.load(schemas_file)\n",
    "\n",
    "column_details = schemas_dict['orders']\n",
    "\n",
    "[c['column_name'] for c in column_details]\n",
    "\n",
    "list(map(lambda c: c['column_name'], column_details))\n",
    "\n",
    "sorted(column_details, key = lambda c: c['data_type'])\n",
    "\n",
    "# \n",
    "# Finished Solution Below\n",
    "# \n",
    "\n",
    "def get_column_names(schemas, table_name, sorting_key='column_position'):   # NOTE: Default Arguments!\n",
    "    column_details = schemas[table_name]\n",
    "    sorted_column_details = sorted(column_details, key = lambda cd: cd[sorting_key])\n",
    "    return list(map(lambda scd: scd['column_name'], sorted_column_details))\n",
    "\n",
    "\n",
    "get_column_names(schemas_dict, 'orders', 'column_name') # Overriding the Default Argument for Sorting Key\n",
    "\n",
    "# \n",
    "# All in one line, just for fun!\n",
    "# \n",
    "\n",
    "# def get_column_names(dict, table_name, sorting_key):\n",
    "#     return list(map(lambda std: std['column_name'], sorted(dict[table_name], key = lambda td: td[sorting_key])))\n",
    "\n",
    "# get_column_names(schemas_dict, 'orders', 'column_name')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing with Pandas and Dataframe APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Manipulating CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "orders_columns = [\n",
    "    'order_id',\n",
    "    'order_date',\n",
    "    'order_customer_id',\n",
    "    'order_status'\n",
    "]\n",
    "\n",
    "orders = pd.read_csv('data/retail_db/orders/part-00000', names=orders_columns)\n",
    "\n",
    "# orders.columns\n",
    "\n",
    "# unique values in a given column\n",
    "orders['order_status'].unique\n",
    "\n",
    "# all orders with status COMPLETE\n",
    "orders.query('order_status == \"COMPLETE\"')\n",
    "\n",
    "# all COMPLETE orders on 1 JAN 2014\n",
    "orders.query('order_status == \"COMPLETE\" and order_date == \"2014-01-01 00:00:00.0\"')\n",
    "\n",
    "# all orders that are COMPLETE or CLOSED\n",
    "orders.query('order_status == \"COMPLETE\" or order_status == \"CLOSED\"')\n",
    "\n",
    "# all orders that are COMPLETE or CLOSED, IN syntax\n",
    "orders.query('order_status == (\"COMPLETE\", \"CLOSED\")')\n",
    "\n",
    "# count orders in each status\n",
    "orders.groupby('order_status')['order_id'].agg(order_count='count')\n",
    "\n",
    "# transform order date into order month, and add this to the data frame\n",
    "# axis = 1 ensures the apply function starts at the first column in the data, rather than the generated row number.\n",
    "orders['order_month'] = orders.apply(lambda order: order.order_date[:7], axis = 1)\n",
    "\n",
    "orders.groupby(['order_month', 'order_status'])['order_id'].agg(order_count='count')\n",
    "\n",
    "# reset index makes the keys (month and status) column names in the resulting data frame.\n",
    "orders.groupby(['order_month', 'order_status'])['order_id'].agg(order_count='count').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Data Frames, Joins and Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# read the content of the schemas file into a Dict\n",
    "schemas = json.load(open('data/retail_db/schemas.json'))\n",
    "\n",
    "# function to extract the column names from a Dict called 'schemas'\n",
    "def get_column_names(schemas, dataset_name, sorting_key='column_position'):\n",
    "    column_details = schemas[dataset_name]\n",
    "    columns = sorted(column_details, key = lambda col: col[sorting_key])\n",
    "    return [col['column_name'] for col in columns]\n",
    "\n",
    "orders_columns = get_column_names(schemas, 'orders')\n",
    "orders = pd.read_csv('data/retail_db/orders/part-00000', names=orders_columns)\n",
    "# set the index for the join we're about to make\n",
    "orders.set_index('order_customer_id')\n",
    "\n",
    "customers_columns = get_column_names(schemas, 'customers')\n",
    "customers = pd.read_csv('data/retail_db/customers/part-00000', names=customers_columns)\n",
    "customers.set_index('customer_id')\n",
    "\n",
    "# join the two dataframes\n",
    "# does LEFT OUTER JOIN by default, override with \"HOW\"\n",
    "customer_orders = customers.join(orders, how='inner')\n",
    "\n",
    "# show the number of rows and columns in a dataframe\n",
    "customer_orders.shape\n",
    "\n",
    "# group the dataframe by Customer ID, then count the number of Orders per Customer and only display when there's 1 or more\n",
    "customer_orders.groupby('customer_id')['customer_id'].agg(order_count='count').reset_index().query('order_count >= 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# read the content of the schemas file into a Dict\n",
    "schemas = json.load(open('data/retail_db/schemas.json'))\n",
    "\n",
    "# function to extract the column names from a Dict called 'schemas'\n",
    "def get_column_names(schemas, dataset_name, sorting_key='column_position'):\n",
    "    column_details = schemas[dataset_name]\n",
    "    columns = sorted(column_details, key = lambda col: col[sorting_key])\n",
    "    return [col['column_name'] for col in columns]\n",
    "\n",
    "orders_columns = get_column_names(schemas, 'orders')\n",
    "orders = pd.read_csv('data/retail_db/orders/part-00000', names=orders_columns)\n",
    "\n",
    "orders.sort_values('order_customer_id')\n",
    "\n",
    "orders.sort_values('order_customer_id', ascending=False)\n",
    "\n",
    "# sort by two values, in opposite directions (ASC/DESC)\n",
    "orders.sort_values(['order_customer_id', 'order_date'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Dataframes to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# read the content of the schemas file into a Dict\n",
    "schemas = json.load(open('data/retail_db/schemas.json'))\n",
    "\n",
    "# function to extract the column names from a Dict called 'schemas'\n",
    "def get_column_names(schemas, dataset_name, sorting_key='column_position'):\n",
    "    column_details = schemas[dataset_name]\n",
    "    columns = sorted(column_details, key = lambda col: col[sorting_key])\n",
    "    return [col['column_name'] for col in columns]\n",
    "\n",
    "orders_columns = get_column_names(schemas, 'orders')\n",
    "orders = pd.read_csv('data/retail_db/orders/part-00000', names=orders_columns)\n",
    "\n",
    "os.makedirs('data/retail_db/orders_json', exist_ok=True)\n",
    "\n",
    "# write data to a file in JSON format, with one record per line\n",
    "orders.to_json('data/retail_db/orders_json/part-00000', orient='records', lines=True)\n",
    "\n",
    "pd.read_json('data/retail_db/orders_json/part-00000', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Bulk Convert CSVs to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# function to extract the column names from a Dict called 'schemas'\n",
    "def get_column_names(schemas, dataset_name, sorting_key='column_position'):\n",
    "    column_details = schemas[dataset_name]\n",
    "    columns = sorted(column_details, key = lambda col: col[sorting_key])\n",
    "    return [col['column_name'] for col in columns]\n",
    "\n",
    "filenames = glob.glob('data/retail_db/*')\n",
    "filenames = list(filter(lambda sf: sf.find('.') == -1, filenames))\n",
    "filenames = list(filter(lambda sf: sf.find('_json') == -1, filenames))\n",
    "\n",
    "stripped_dirs_and_files = [f.replace('data/retail_db/', '') for f in filenames]\n",
    "\n",
    "dataset_names = list(filter(lambda sf: sf.find('.') == -1, stripped_dirs_and_files))\n",
    "dataset_names = list(filter(lambda sf: sf.find('_json') == -1, dataset_names))\n",
    "\n",
    "dataset_names\n",
    "\n",
    "dataset_dirs = list(filter(lambda sf: sf.find('.') == -1, filenames))\n",
    "dataset_files = list(map(lambda dir: format(dir + '/part-00000'), dataset_dirs))\n",
    "\n",
    "dataset_details = []\n",
    "\n",
    "for name in dataset_names:\n",
    "    for dir in dataset_files:\n",
    "        if (dir.find(name) != -1):\n",
    "            dataset_details.append((name, dir))\n",
    "\n",
    "# read the content of the schemas file into a Dict\n",
    "schemas = json.load(open('data/retail_db/schemas.json'))\n",
    "\n",
    "def convert_csv_dataset_to_json(pd_library, os_library, dataset, dataset_file):\n",
    "    column_names = get_column_names(schemas, dataset)\n",
    "    dataset_csv = pd_library.read_csv(dataset_file, names=column_names)\n",
    "    \n",
    "    os_library.makedirs('data/retail_db/' + dataset + '_json', exist_ok=True)\n",
    "    dataset_csv.to_json('data/retail_db/' + dataset + '_json/part-00000', orient='records', lines=True)\n",
    "    \n",
    "    dataset_json = pd_library.read_json('data/retail_db/' + dataset + '_json/part-00000', lines=True)\n",
    "\n",
    "    if (dataset_json.shape[0] == dataset_csv.shape[0]):\n",
    "        print(str(dataset_json.shape[0]) + ' ' + str.capitalize(dataset) + ' records converted.')\n",
    "\n",
    "for details in dataset_details:\n",
    "    convert_csv_dataset_to_json(pd, os, details[0], details[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# function to extract the column names from a Dict called 'schemas'\n",
    "def get_column_names(schemas, dataset_name, sorting_key='column_position'):\n",
    "    column_details = schemas[dataset_name]\n",
    "    columns = sorted(column_details, key = lambda col: col[sorting_key])\n",
    "    return [col['column_name'] for col in columns]\n",
    "\n",
    "output_base_dir = 'data/retail_db_json'\n",
    "\n",
    "files = glob.glob('data/retail_db/*/part-*')\n",
    "schemas = json.load(open('data/retail_db/schemas.json'))\n",
    "\n",
    "for file in files:\n",
    "    file_path_tokens = file.split('/') \n",
    "    dataset_name = file_path_tokens[-2]\n",
    "    file_name = file_path_tokens[-1]\n",
    "    \n",
    "    column_names = get_column_names(schemas, dataset_name)\n",
    "    file_data = pd.read_csv(file, names=column_names)\n",
    "\n",
    "    json_folder_path = f'{output_base_dir}/{dataset_name}' \n",
    "    json_file_path = f'{json_folder_path}/{file_name}'\n",
    "    print(f'Shape of {file} is {file_data.shape}')\n",
    "    print(f'Destination is {json_file_path}')\n",
    "\n",
    "    os.makedirs(f'{json_folder_path}', exist_ok=True)\n",
    "    file_data.to_json(json_file_path, orient='records', lines=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: CSVs to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting Notebooks (and Python) to the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipython-sql\n",
    "!pip install psycopg2-binary\n",
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env RETAIL_DB_HOST=localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.get('RETAIL_DB_HOST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%env DATABASE_URL=postgresql://retail_user:retail_password@localhost:5432/retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM orders LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "conn_uri = 'postgresql://retail_user:retail_password@localhost:5432/retail_db'\n",
    "\n",
    "pd.read_sql('orders', conn_uri)\n",
    "\n",
    "query = '''\n",
    "    SELECT order_status, count(*) as order_count\n",
    "    FROM orders\n",
    "    GROUP BY order_status\n",
    "    ORDER BY order_count DESC\n",
    "'''\n",
    "\n",
    "pd.read_sql_query(query, conn_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%env DATABASE_URL=postgresql://retail_user:retail_password@localhost:5432/retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "TRUNCATE TABLE orders CASCADE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_column_names(schemas, dataset_name, sorting_key='column_position'):\n",
    "    column_details = schemas[dataset_name]\n",
    "    columns = sorted(column_details, key = lambda col: col[sorting_key])\n",
    "    return [col['column_name'] for col in columns]\n",
    "\n",
    "schemas = json.load(open('data/retail_db/schemas.json'))\n",
    "conn_uri = 'postgresql://retail_user:retail_password@localhost:5432/retail_db'\n",
    "\n",
    "column_names = get_column_names(schemas, 'orders')\n",
    "\n",
    "dataframe = pd.read_csv('data/retail_db/orders/part-00000', names=column_names)\n",
    "\n",
    "dataframe.to_sql(\n",
    "    'orders',\n",
    "    conn_uri,\n",
    "    if_exists='append',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "pd.read_sql('orders', conn_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunked Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_column_names(schemas, dataset_name, sorting_key='column_position'):\n",
    "    column_details = schemas[dataset_name]\n",
    "    columns = sorted(column_details, key = lambda col: col[sorting_key])\n",
    "    return [col['column_name'] for col in columns]\n",
    "\n",
    "schemas = json.load(open('data/retail_db/schemas.json'))\n",
    "conn_uri = 'postgresql://retail_user:retail_password@localhost:5432/retail_db'\n",
    "\n",
    "column_names = get_column_names(schemas, 'orders')\n",
    "\n",
    "dataframe_reader = pd.read_csv('data/retail_db/orders/part-00000', names=column_names, chunksize=10000)\n",
    "\n",
    "dataframe_chunk_list = list(dataframe_reader)\n",
    "\n",
    "for idx, chunk in enumerate(dataframe_chunk_list):\n",
    "    print(f'Processing Chunk {idx} with size {chunk.shape} of Orders')\n",
    "    chunk.to_sql(\n",
    "        'orders',\n",
    "        conn_uri,\n",
    "        if_exists='append',\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreading in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleeping for 2\n",
      "sleeping for 1\n",
      "sleeping for 2\n",
      "sleeping for 3\n",
      "sleeping for 4\n",
      "sleeping for 2\n",
      "sleeping for 3\n",
      "sleeping for 5\n",
      "sleeping for 3\n",
      "sleeping for 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from mp_demo import my_sleep\n",
    "\n",
    "times = [1,2,3,2,4,2,3,5,3,2]\n",
    "\n",
    "len(times)\n",
    "\n",
    "# for time in times:\n",
    "#     print(f'sleeping for {time}')\n",
    "#     time.sleep(time)\n",
    "\n",
    "# find out how many cores your mac has with: sysctl -a | grep machdep.cpu\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "pool = multiprocessing.Pool(4) # create an execution pool of 4 threads\n",
    "\n",
    "# multithreaded sleeping\n",
    "# pool.map(time.sleep, times)\n",
    "\n",
    "pool.map(my_sleep, times)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pr-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
